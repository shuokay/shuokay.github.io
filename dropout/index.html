<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"shuokay.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Dropout 是一种非常非常通用的解决深层神经网络中 overfitting 问题的方法, 过程极其简单, 在调试算法中效果也非常有效, 几乎是在设计网络过程中必用的技巧.">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN 基础之 Dropout">
<meta property="og:url" content="http://shuokay.com/dropout/index.html">
<meta property="og:site_name" content="Memo">
<meta property="og:description" content="Dropout 是一种非常非常通用的解决深层神经网络中 overfitting 问题的方法, 过程极其简单, 在调试算法中效果也非常有效, 几乎是在设计网络过程中必用的技巧.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://shuokay.com/content/images/dropout/dropout.png">
<meta property="article:published_time" content="2016-06-14T12:50:19.000Z">
<meta property="article:modified_time" content="2022-08-13T02:16:25.725Z">
<meta property="article:author" content="yushu.gao">
<meta property="article:tag" content="CNN">
<meta property="article:tag" content="MXNet">
<meta property="article:tag" content="Caffe">
<meta property="article:tag" content="Dropout">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://shuokay.com/content/images/dropout/dropout.png">

<link rel="canonical" href="http://shuokay.com/dropout/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>CNN 基础之 Dropout | Memo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Memo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://shuokay.com/dropout/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="yushu.gao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Memo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CNN 基础之 Dropout
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-06-14 20:50:19" itemprop="dateCreated datePublished" datetime="2016-06-14T20:50:19+08:00">2016-06-14</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CNN/" itemprop="url" rel="index"><span itemprop="name">CNN</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CNN/Op/" itemprop="url" rel="index"><span itemprop="name">Op</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Dropout 是一种非常非常通用的解决深层神经网络中 overfitting 问题的方法, 过程极其简单, 在调试算法中效果也非常有效, 几乎是在设计网络过程中必用的技巧.</p>
<span id="more"></span>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>深层神经网络的参数非常非常多, 一般情况下设计的神经网络非常容易 overfitting, 在 CNN 中, Pooling 层具有一定的防止 overfitting 的作用, 但是, CNN 的结构一般是多个 conv factory 之后需要使用 full connect 来做分类等任务, 由于在 full connect layer 中参数密度比较高, 非常容易 overfitting, 而 Dropout 可以用来解决这里的 overfitting 问题[^1].</p>
<h1 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h1><center><img src="/content/images/dropout/dropout.png" width=500></center>
如上图, 左边是我们常见的 full connect layer, 右边是使用了 dropout 之后的效果. 其操作方法是, 首先设定一个 dropout ratio \\(\\sigma\\), \\(\sigma\\) 是超参数, 范围设置为 \\(\left (0,1\right)\\), 表示在 Forward 阶段需要随机断开的连接的比例. 每次 Forward 的时候都要随机的断开该比例的连接, 只更新剩下的 weight. 最后, 在 test/predict 的时候, 使用全部的连接, 不过, 这些 weights 全部都需要乘上 \\(1-\sigma\\). 不过, 在具体的实现中略有不同, 参下面的源码解释.

<h1 id="Side-Effect"><a href="#Side-Effect" class="headerlink" title="Side Effect"></a>Side Effect</h1><p>Dropout 除了具有防止 overfitting 的作用之外, 还有 model ensemble 的作用.<br>我们考虑, 假设 \(\sigma&#x3D;0.5\), 如果 Forward 的次数足够多(例如无穷次), 每次都有一半的连接被咔嚓掉, 在整个训练过程中, 被咔嚓掉的连接的组合是 \(2^n\), 那么, 留下的连接的组合种类也是 \(2^n\), 所以, 这就相当于我们训练了 \(2^n\) 个模型, 然后 ensemble 起来.</p>
<h1 id="MXNet-源码"><a href="#MXNet-源码" class="headerlink" title="MXNet 源码"></a>MXNet 源码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> xpu&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropoutOp</span> : <span class="keyword">public</span> Operator &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">DropoutOp</span><span class="params">(DropoutParam param)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// param.p 是 dropout ratio</span></span><br><span class="line">    <span class="keyword">this</span>-&gt;pkeep_ = <span class="number">1.0f</span> - param.p;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Forward</span><span class="params">(<span class="type">const</span> OpContext &amp;ctx,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> std::vector&lt;TBlob&gt; &amp;in_data,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> std::vector&lt;OpReqType&gt; &amp;req,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> std::vector&lt;TBlob&gt; &amp;out_data,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> std::vector&lt;TBlob&gt; &amp;aux_states)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> mshadow;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> mshadow::expr;</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(in_data.<span class="built_in">size</span>(), <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (ctx.is_train) &#123;</span><br><span class="line">      <span class="built_in">CHECK_EQ</span>(out_data.<span class="built_in">size</span>(), <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Stream&lt;xpu&gt; *s = ctx.<span class="built_in">get_stream</span>&lt;xpu&gt;();</span><br><span class="line">    Tensor&lt;xpu, <span class="number">2</span>&gt; data = in_data[dropout::kData].<span class="built_in">FlatTo2D</span>&lt;xpu, <span class="type">real_t</span>&gt;(s);</span><br><span class="line">    Tensor&lt;xpu, <span class="number">2</span>&gt; out = out_data[dropout::kOut].<span class="built_in">FlatTo2D</span>&lt;xpu, <span class="type">real_t</span>&gt;(s);</span><br><span class="line">    <span class="keyword">if</span> (ctx.is_train) &#123;</span><br><span class="line">      Tensor&lt;xpu, <span class="number">2</span>&gt; mask = out_data[dropout::kMask].<span class="built_in">FlatTo2D</span>&lt;xpu, <span class="type">real_t</span>&gt;(s);</span><br><span class="line">      Random&lt;xpu&gt; *prnd = ctx.requested[dropout::kRandom].<span class="built_in">get_random</span>&lt;xpu, <span class="type">real_t</span>&gt;(s);</span><br><span class="line">      <span class="comment">// 均匀采样, 采样概率是留下的概率, 根据这个概率来咔嚓连接, 但是, 把留下的值全部除以pkeep,</span></span><br><span class="line">      <span class="comment">// 这样, 在 test/predict 的时候就不需要像上面描述的那样乘以 1-sigma 了</span></span><br><span class="line">      mask = <span class="built_in">F</span>&lt;mshadow_op::threshold&gt;(prnd-&gt;<span class="built_in">uniform</span>(mask.shape_), pkeep_) * (<span class="number">1.0f</span> / pkeep_);</span><br><span class="line">      <span class="built_in">Assign</span>(out, req[dropout::kOut], data * mask);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">Assign</span>(out, req[dropout::kOut], <span class="built_in">F</span>&lt;mshadow_op::identity&gt;(data));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="CAFFE-源码"><a href="#CAFFE-源码" class="headerlink" title="CAFFE 源码"></a>CAFFE 源码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> DropoutLayer&lt;Dtype&gt;::<span class="built_in">LayerSetUp</span>(<span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  NeuronLayer&lt;Dtype&gt;::<span class="built_in">LayerSetUp</span>(bottom, top);</span><br><span class="line">  threshold_ = <span class="keyword">this</span>-&gt;layer_param_.<span class="built_in">dropout_param</span>().<span class="built_in">dropout_ratio</span>();</span><br><span class="line">  <span class="built_in">DCHECK</span>(threshold_ &gt; <span class="number">0.</span>);</span><br><span class="line">  <span class="built_in">DCHECK</span>(threshold_ &lt; <span class="number">1.</span>);</span><br><span class="line">  scale_ = <span class="number">1.</span> / (<span class="number">1.</span> - threshold_);</span><br><span class="line">  uint_thres_ = <span class="built_in">static_cast</span>&lt;<span class="type">unsigned</span> <span class="type">int</span>&gt;(UINT_MAX * threshold_);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="type">void</span> DropoutLayer&lt;Dtype&gt;::<span class="built_in">Forward_cpu</span>(<span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">    <span class="type">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="type">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;<span class="built_in">cpu_data</span>();</span><br><span class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;<span class="built_in">mutable_cpu_data</span>();</span><br><span class="line">  <span class="type">unsigned</span> <span class="type">int</span>* mask = rand_vec_.<span class="built_in">mutable_cpu_data</span>();</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> count = bottom[<span class="number">0</span>]-&gt;<span class="built_in">count</span>();</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;phase_ == TRAIN) &#123;</span><br><span class="line">    <span class="comment">// Create random numbers</span></span><br><span class="line">    <span class="comment">// 需要保留的数据</span></span><br><span class="line">    <span class="built_in">caffe_rng_bernoulli</span>(count, <span class="number">1.</span> - threshold_, mask);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; count; ++i) &#123;</span><br><span class="line">      <span class="comment">// 同理MXNet中的解释</span></span><br><span class="line">      top_data[i] = bottom_data[i] * mask[i] * scale_;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">caffe_copy</span>(bottom[<span class="number">0</span>]-&gt;<span class="built_in">count</span>(), bottom_data, top_data);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><h2 id="MXNet"><a href="#MXNet" class="headerlink" title="MXNet"></a>MXNet</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_symbol</span>(<span class="params">num_classes = <span class="number">1000</span></span>):</span><br><span class="line">    input_data = mx.symbol.Variable(name=<span class="string">&quot;data&quot;</span>)</span><br><span class="line">    <span class="comment"># stage 1</span></span><br><span class="line">    conv1 = mx.symbol.Convolution(</span><br><span class="line">        data=input_data, kernel=(<span class="number">11</span>, <span class="number">11</span>), stride=(<span class="number">4</span>, <span class="number">4</span>), num_filter=<span class="number">96</span>)</span><br><span class="line">    relu1 = mx.symbol.Activation(data=conv1, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    pool1 = mx.symbol.Pooling(</span><br><span class="line">        data=relu1, pool_type=<span class="string">&quot;max&quot;</span>, kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">    lrn1 = mx.symbol.LRN(data=pool1, alpha=<span class="number">0.0001</span>, beta=<span class="number">0.75</span>, knorm=<span class="number">1</span>, nsize=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># stage 2</span></span><br><span class="line">    conv2 = mx.symbol.Convolution(</span><br><span class="line">        data=lrn1, kernel=(<span class="number">5</span>, <span class="number">5</span>), pad=(<span class="number">2</span>, <span class="number">2</span>), num_filter=<span class="number">256</span>)</span><br><span class="line">    relu2 = mx.symbol.Activation(data=conv2, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    pool2 = mx.symbol.Pooling(data=relu2, kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">&quot;max&quot;</span>)</span><br><span class="line">    lrn2 = mx.symbol.LRN(data=pool2, alpha=<span class="number">0.0001</span>, beta=<span class="number">0.75</span>, knorm=<span class="number">1</span>, nsize=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># stage 3</span></span><br><span class="line">    conv3 = mx.symbol.Convolution(</span><br><span class="line">        data=lrn2, kernel=(<span class="number">3</span>, <span class="number">3</span>), pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">384</span>)</span><br><span class="line">    relu3 = mx.symbol.Activation(data=conv3, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    conv4 = mx.symbol.Convolution(</span><br><span class="line">        data=relu3, kernel=(<span class="number">3</span>, <span class="number">3</span>), pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">384</span>)</span><br><span class="line">    relu4 = mx.symbol.Activation(data=conv4, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    conv5 = mx.symbol.Convolution(</span><br><span class="line">        data=relu4, kernel=(<span class="number">3</span>, <span class="number">3</span>), pad=(<span class="number">1</span>, <span class="number">1</span>), num_filter=<span class="number">256</span>)</span><br><span class="line">    relu5 = mx.symbol.Activation(data=conv5, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    pool3 = mx.symbol.Pooling(data=relu5, kernel=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), pool_type=<span class="string">&quot;max&quot;</span>)</span><br><span class="line">    <span class="comment"># stage 4</span></span><br><span class="line">    flatten = mx.symbol.Flatten(data=pool3)</span><br><span class="line">    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=<span class="number">4096</span>)</span><br><span class="line">    relu6 = mx.symbol.Activation(data=fc1, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    <span class="comment"># dropout 的使用, 在 full connect 后面</span></span><br><span class="line">    dropout1 = mx.symbol.Dropout(data=relu6, p=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># stage 5</span></span><br><span class="line">    fc2 = mx.symbol.FullyConnected(data=dropout1, num_hidden=<span class="number">4096</span>)</span><br><span class="line">    relu7 = mx.symbol.Activation(data=fc2, act_type=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">    <span class="comment"># dropout, 直接接在 full connect 后面</span></span><br><span class="line">    dropout2 = mx.symbol.Dropout(data=relu7, p=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># stage 6</span></span><br><span class="line">    fc3 = mx.symbol.FullyConnected(data=dropout2, num_hidden=num_classes)</span><br><span class="line">    softmax = mx.symbol.SoftmaxOutput(data=fc3, name=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> softmax</span><br></pre></td></tr></table></figure>

<h2 id="CAFFE"><a href="#CAFFE" class="headerlink" title="CAFFE"></a>CAFFE</h2><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">  type: <span class="string">&quot;InnerProduct&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;pool5&quot;</span></span><br><span class="line">  top: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">    decay_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">    decay_mult: <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">4096</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">&quot;gaussian&quot;</span></span><br><span class="line">      std: <span class="number">0.005</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: <span class="string">&quot;constant&quot;</span></span><br><span class="line">      value: <span class="number">0.1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;relu6&quot;</span></span><br><span class="line">  type: <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">  top: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"># 方法类似, 接在 full connect 后面, 指定 dropout ratio</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;drop6&quot;</span></span><br><span class="line">  type: <span class="string">&quot;Dropout&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">  top: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: <span class="number">0.5</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;fc7&quot;</span></span><br><span class="line">  type: <span class="string">&quot;InnerProduct&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;fc6&quot;</span></span><br><span class="line">  top: <span class="string">&quot;fc7&quot;</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">    decay_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">    decay_mult: <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: <span class="number">4096</span></span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: <span class="string">&quot;gaussian&quot;</span></span><br><span class="line">      std: <span class="number">0.005</span></span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: <span class="string">&quot;constant&quot;</span></span><br><span class="line">      value: <span class="number">0.1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;relu7&quot;</span></span><br><span class="line">  type: <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;fc7&quot;</span></span><br><span class="line">  top: <span class="string">&quot;fc7&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;drop7&quot;</span></span><br><span class="line">  type: <span class="string">&quot;Dropout&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;fc7&quot;</span></span><br><span class="line">  top: <span class="string">&quot;fc7&quot;</span></span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: <span class="number">0.5</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>[^1]: 最近也有一些网络不使用 Dropout, 例如: Network in Network 使用的是 global average pooling 来 handle 的 overfitting 问题, 以及 Kaiming 的 Residual Network 也没有使用 dropout, Residual Net 甚至没有使用 Pooling, 而是用 convolution 操作来搞定的降维问题.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CNN/" rel="tag"># CNN</a>
              <a href="/tags/MXNet/" rel="tag"># MXNet</a>
              <a href="/tags/Caffe/" rel="tag"># Caffe</a>
              <a href="/tags/Dropout/" rel="tag"># Dropout</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/optimization/" rel="prev" title="卷积神经网络中的优化算法比较">
      <i class="fa fa-chevron-left"></i> 卷积神经网络中的优化算法比较
    </a></div>
      <div class="post-nav-item">
    <a href="/hog/" rel="next" title="HOG 特征解释">
      HOG 特征解释 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">具体过程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Side-Effect"><span class="nav-number">3.</span> <span class="nav-text">Side Effect</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MXNet-%E6%BA%90%E7%A0%81"><span class="nav-number">4.</span> <span class="nav-text">MXNet 源码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CAFFE-%E6%BA%90%E7%A0%81"><span class="nav-number">5.</span> <span class="nav-text">CAFFE 源码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">使用方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MXNet"><span class="nav-number">6.1.</span> <span class="nav-text">MXNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CAFFE"><span class="nav-number">6.2.</span> <span class="nav-text">CAFFE</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">yushu.gao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">92</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">94</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yushu.gao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
